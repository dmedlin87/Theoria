<!-- Generated by scripts/docs/create_agent_context.py -->

> Generated: 2025-10-25 19:16:54 UTC
> Source commit: 8f144411c9db11b77247653f87d8d2f99900cdbd
> Branch: work
> Remote: unknown
> Source files:
> - AGENT_HANDOFF_COMPLETE.md
> - HANDOFF_SESSION_2025_10_15.md
> - HANDOFF_MYPY_FIXES_2025_10_17.md
> - HANDOFF_NEXT_PHASE.md
> - IMPLEMENTATION_CONTEXT.md

---

## Agent Handoff Package

## Agent Handoff - Complete Package

### 📦 Handoff Documents Created

Your AI agents have everything they need to continue development:

#### 1. **HANDOFF_SESSION_2025_10_15.md** - Session Summary
- What was completed this session
- Current system state (what's working, what's missing)
- Next steps in priority order
- Deployment instructions
- Testing strategy
- Configuration options

#### 2. **IMPLEMENTATION_CONTEXT.md** - Technical Guide
- Architecture patterns (hexagonal, discovery engine pattern)
- Code style & conventions (Python, TypeScript)
- Testing patterns (unit, integration)
- Database patterns (models, queries)
- API patterns (FastAPI routes, Pydantic models)
- Common pitfalls & solutions
- Development workflow
- Environment setup
- Debugging tips
- Key dependencies

#### 3. **QUICK_START_FOR_AGENTS.md** - Immediate Action Plan
- Condensed quick-start guide
- Next task: Cognitive Gate v0 + Hypothesis Objects
- Complete implementation steps with code examples
- Testing instructions
- Follow-on checklist through TMS and Debate v0

#### 4. **HANDOFF_NEXT_PHASE.md** - Long-term Roadmap
- 6-8 week Cognitive Scholar delivery plan
- Phase 1: Hypothesis Objects & Cognitive Gate v0 (Week 1-2)
- Phase 2: POU Loop Swap & Research UI Refresh (Week 3)
- Phase 3: Thought Management System (TMS) v0 (Week 4-5)
- Phase 4: Debate Loop v0 & Visualization Layer v1 (Week 6)
- Phase 5: Meta-Prompt Picker & Beta Hardening (Week 7-8)
- Success metrics for each phase

---

### ✅ What's Complete

#### This Session
1. **Background Discovery Scheduler**
   - APScheduler integration
   - Runs every 30 minutes
   - Finds active users and refreshes discoveries
   - Graceful startup/shutdown

2. **Contradiction Detection Engine**
   - NLI-based (DeBERTa-v3-base-mnli)
   - Pairwise document comparison
   - Contradiction type inference
   - Full test coverage

3. **Comprehensive Documentation**
   - Agent architecture guide
   - Scheduler documentation
   - Contradiction detection guide
   - Implementation patterns

#### Previously Complete
- Frontend UI (Next.js, complete and polished)
- RAG pipeline with guardrails
- Pattern detection (DBSCAN clustering)
- Background tasks after uploads
- Discovery API endpoints
- Database schema

---

### 🎯 What's Next (Priority Order)

#### Phase 1: Complete Discovery Engine

**1.2 Gap Analysis** ⭐ HIGH PRIORITY - START HERE
- Detect missing topics using BERTopic
- Compare against reference theological topics
- File: `theo/domain/discoveries/gap_engine.py`
- Dependency: `bertopic>=0.15,<1`

**1.3 Connection Detection** - MEDIUM PRIORITY
- Graph-based analysis of shared verses
- Find bridge documents
- File: `theo/domain/discoveries/connection_engine.py`
- Dependency: `networkx>=3.0,<4`

**1.4 Trend Detection** - MEDIUM PRIORITY
- Time-series analysis of topics
- Compare current vs historical snapshots
- File: `theo/domain/discoveries/trend_engine.py`
- Requires 3+ corpus snapshots

**1.5 Anomaly Detection** - LOW PRIORITY
- Isolation forest for outlier detection
- File: `theo/domain/discoveries/anomaly_engine.py`
- Uses sklearn (already installed)

#### Phase 2: Expose Agent Reasoning in UI

**2.1 Reasoning Mode Toggle** ⭐ HIGH PRIORITY
- Add mode selector to chat UI
- Modes: detective/critic/apologist/synthesizer
- Files: `theo/services/web/app/chat/page.tsx`, `theo/services/api/app/ai/router.py`

**2.2 Display Reasoning Trace**
- Show step-by-step reasoning
- File: `theo/services/web/components/ReasoningTrace.tsx`

**2.3 Fallacy Warnings**
- Highlight logical errors
- File: `theo/services/web/components/FallacyWarnings.tsx`

**2.4 Hypothesis Dashboard**
- Track and test hypotheses
- File: `theo/services/web/app/research/hypotheses/page.tsx`

#### Phase 3: Personalized Dashboard

- Replace landing page
- Quick stats, recent activity, discoveries
- Files: `theo/services/web/app/page.tsx`, `theo/services/api/app/routes/dashboard.py`

#### Phase 4: Citation Manager

- Export citations (APA/Chicago/SBL/BibTeX)
- Bibliography builder
- Zotero integration (optional)
- Files: `theo/services/api/app/export/citations.py`, `theo/services/web/components/CitationExport.tsx`

---

### 📚 Key Reference Files

#### Examples to Follow
- `theo/domain/discoveries/engine.py` - Pattern detection (reference implementation)
- `theo/domain/discoveries/contradiction_engine.py` - Just implemented (best example)
- `theo/services/api/app/discoveries/service.py` - Integration point

#### Documentation
- `docs/INDEX.md` - Master documentation index
- `docs/AGENT_AND_PROMPTING_GUIDE.md` - Agent architecture
- `docs/DISCOVERY_FEATURE.md` - Discovery system spec
- `docs/DISCOVERY_SCHEDULER.md` - Scheduler details
- `docs/CONTRADICTION_DETECTION.md` - Contradiction implementation

#### Existing Code
- `theo/services/api/app/main.py` - FastAPI app with scheduler
- `theo/services/api/app/routes/discoveries.py` - API endpoints
- `theo/services/web/app/discoveries/page.tsx` - Frontend UI

---

### 🚀 Quick Start for Your Agents

#### Step 1: Read Documentation
1. Start with `QUICK_START_FOR_AGENTS.md` (immediate action plan)
2. Reference `IMPLEMENTATION_CONTEXT.md` (patterns and conventions)
3. Check `HANDOFF_SESSION_2025_10_15.md` (current state)

#### Step 2: Set Up Environment
```bash
## Install dependencies
pip install -r requirements.txt

## Start services
.\start-theoria.ps1

## Verify scheduler is running
## Check logs for: "Discovery scheduler started successfully"
```

#### Step 3: Implement Gap Analysis
Follow the complete implementation in `QUICK_START_FOR_AGENTS.md`:
1. Create `theo/domain/discoveries/gap_engine.py`
2. Create `data/seeds/theological_topics.yaml`
3. Write tests in `tests/domain/discoveries/test_gap_engine.py`
4. Integrate into `DiscoveryService`
5. Add `bertopic>=0.15,<1` to `requirements.txt`
6. Export from `theo/domain/discoveries/__init__.py`

#### Step 4: Test
```bash
## Unit tests
pytest tests/domain/discoveries/test_gap_engine.py -v

## Integration tests
pytest tests/api/test_discovery_integration.py -v

## Manual test
curl http://localhost:8000/api/discoveries?type=gap
```

#### Step 5: Continue with Next Discovery Type
Repeat pattern for Connection, Trend, and Anomaly detection.

---

### 📊 Progress Tracking

#### Discovery Engine Status
- ✅ Pattern Detection (DBSCAN clustering)
- ✅ Contradiction Detection (NLI-based)
- ❌ Gap Analysis (BERTopic) ← **START HERE**
- ❌ Connection Detection (graph-based)
- ❌ Trend Detection (time-series)
- ❌ Anomaly Detection (isolation forest)

**Progress:** 2/6 complete (33%)

#### Overall Project Status
- ✅ Phase 1.1: Contradiction Detection
- ❌ Phase 1.2-1.5: Remaining discovery types
- ❌ Phase 2: Agent reasoning UI
- ❌ Phase 3: Personalized dashboard
- ❌ Phase 4: Citation manager

**Estimated Timeline:** 6-8 weeks to complete Cognitive Scholar phases

---

### 🔧 Development Workflow

#### For Each Feature
1. **Create domain logic** - Pure Python, no dependencies
2. **Write tests** - TDD approach, unit + integration
3. **Integrate into service** - Add to `DiscoveryService`
4. **Update API** - Ensure endpoints work
5. **Test manually** - Upload docs, check results
6. **Document** - Update relevant .md files

#### Code Quality
```bash
## Type checking
mypy theo/

## Linting
ruff check theo/
ruff format theo/

## Tests with coverage
pytest tests/ --cov=theo --cov-report=html
```

---

### 🎯 Success Criteria

#### Phase 1 Complete When:
- [ ] All 6 discovery types generating discoveries
- [ ] Average 10+ discoveries per user with 50+ documents
- [ ] Discovery generation < 30s for typical corpus
- [ ] All tests passing
- [ ] Documentation updated

#### Phase 2 Complete When:
- [ ] Reasoning modes selectable in chat UI
- [ ] Reasoning traces display correctly
- [ ] Fallacy warnings show up
- [ ] Hypothesis dashboard functional

#### Phase 3 Complete When:
- [ ] Dashboard replaces landing page
- [ ] Stats display correctly
- [ ] Recent activity shows
- [ ] Quick actions work

#### Phase 4 Complete When:
- [ ] Citations export in all formats
- [ ] Bibliography builder works
- [ ] Copy/download functionality works

---

### 💡 Tips for Your Agents

#### Pattern to Follow
Look at `theo/domain/discoveries/contradiction_engine.py` - it's the best example because it was just implemented. Copy its structure:

1. **Dataclass for discovery result** (frozen=True)
2. **Engine class with __init__ for config**
3. **Lazy loading for expensive resources** (_load_model pattern)
4. **detect() method that returns list of discoveries**
5. **Helper methods prefixed with _**
6. **Comprehensive docstrings**
7. **Type hints everywhere**

#### Common Patterns
- Use `from __future__ import annotations` for forward refs
- Lazy load ML models to avoid startup delays
- Batch process large datasets
- Use context managers for database sessions
- Return empty list for insufficient data (don't error)
- Sort by confidence (highest first)
- Limit results to top N (avoid overwhelming users)

#### Testing Strategy
- Test initialization
- Test with valid input
- Test with edge cases (empty, too few, invalid)
- Test with realistic data
- Mark slow tests with `@pytest.mark.slow`
- Use fixtures for test data

---

### 📞 Support

All context is in the documentation. If agents need clarification:

1. Check `IMPLEMENTATION_CONTEXT.md` for patterns
2. Look at existing engines for examples
3. Review `docs/DISCOVERY_FEATURE.md` for requirements
4. Examine tests for expected behavior

---

### ✨ Final Notes

#### What Makes This Handoff Complete

1. **Clear starting point** - Cognitive Gate v0 + Hypothesis Objects ready with full implementation guide
2. **Complete context** - Architecture, patterns, conventions all documented
3. **Working examples** - Discovery engines and reasoning flows illustrate patterns
4. **Test coverage** - Patterns and examples for testing
5. **Roadmap** - Clear path for the next 6-8 weeks of Cognitive Scholar delivery
6. **Success criteria** - Know when each Cognitive Scholar phase is done

#### Your Agents Can Now:
- ✅ Understand the architecture
- ✅ Follow established patterns
- ✅ Implement new discovery types
- ✅ Write appropriate tests
- ✅ Integrate into existing system
- ✅ Continue through all 4 phases

---

**Everything is ready. Your agents can start with Gap Analysis immediately.** 🚀

**Status:** Handoff complete  
**Next Task:** Phase 1.2 - Gap Analysis  
**Reference:** `QUICK_START_FOR_AGENTS.md`

---

## Session Summary (2025-10-15)

## Theoria Development Session - October 15, 2025

### Executive Summary

This session implemented **background auto-discovery** and completed **Phase 1.1 (Contradiction Detection)** of the Discovery Engine. The system now automatically generates discoveries in the background using APScheduler and detects contradictions between documents using NLI.

---

### What Was Completed ✅

#### 1. Background Discovery Scheduler
- **File:** `theo/services/api/app/workers/discovery_scheduler.py`
- **Integration:** `theo/services/api/app/main.py` (FastAPI lifecycle)
- **Docs:** `docs/DISCOVERY_SCHEDULER.md`
- **Dependency:** `apscheduler>=3.10,<4`

**Features:**
- Runs every 30 minutes
- Finds users with activity in last 7 days
- Refreshes discoveries automatically
- Graceful startup/shutdown

#### 2. Contradiction Detection Engine
- **File:** `theo/domain/discoveries/contradiction_engine.py`
- **Tests:** `tests/domain/discoveries/test_contradiction_engine.py`
- **Docs:** `docs/CONTRADICTION_DETECTION.md`
- **Dependencies:** `transformers>=4.30,<5`, `torch>=2.0,<3`, `sentencepiece>=0.1.99,<0.2`

**Features:**
- NLI-based detection (DeBERTa-v3-base-mnli)
- Pairwise document comparison
- Contradiction type inference (theological/historical/textual/logical)
- Configurable thresholds

#### 3. Comprehensive Documentation
- `HANDOFF_NEXT_PHASE.md` - 6-8 week Cognitive Scholar roadmap
- `docs/AGENT_AND_PROMPTING_GUIDE.md` - Agent architecture
- `docs/DISCOVERY_SCHEDULER.md` - Scheduler details
- `docs/CONTRADICTION_DETECTION.md` - Implementation guide

---

### Current System State

#### Working ✅
- Frontend UI (complete)
- RAG pipeline with guardrails
- Pattern detection (DBSCAN clustering)
- Contradiction detection (NLI-based) ← NEW
- Background scheduler ← NEW
- Background tasks after uploads

#### Missing ❌
- Gap Analysis (BERTopic)
- Connection Detection (graph-based)
- Trend Detection (time-series)
- Anomaly Detection (isolation forest)
- Agent reasoning UI (framework exists but not exposed)
- Personalized dashboard
- Citation manager

---

### Next Steps (Priority Order)

#### Phase 1: Complete Discovery Engine (Week 1-2)

**1.3 Gap Analysis** (HIGH PRIORITY)
- File: `theo/domain/discoveries/gap_engine.py`
- Use BERTopic for topic modeling
- Compare against reference topics (Christology, Soteriology, etc.)
- Create: `data/seeds/theological_topics.yaml`
- Dependency: `bertopic>=0.15,<1`

**1.4 Connection Detection** (MEDIUM PRIORITY)
- File: `theo/domain/discoveries/connection_engine.py`
- Build graph from shared verse_ids
- Find bridge documents
- Dependency: `networkx>=3.0,<4`

**1.5 Trend Detection** (MEDIUM PRIORITY)
- File: `theo/domain/discoveries/trend_engine.py`
- Time-series analysis of topics
- Compare current vs historical snapshots
- Requires 3+ corpus snapshots

**1.6 Anomaly Detection** (LOW PRIORITY)
- File: `theo/domain/discoveries/anomaly_engine.py`
- Use sklearn IsolationForest
- Identify outliers in embeddings

#### Phase 2: Expose Agent Reasoning (Week 3)

**2.1 Reasoning Mode Toggle**
- Modify: `theo/services/web/app/chat/page.tsx`
- Add modes: detective/critic/apologist/synthesizer
- Backend: `theo/services/api/app/ai/router.py`

**2.2 Display Reasoning Trace**
- Create: `theo/services/web/components/ReasoningTrace.tsx`
- Expandable step-by-step display

**2.3 Fallacy Warnings**
- Create: `theo/services/web/components/FallacyWarnings.tsx`

**2.4 Hypothesis Dashboard**
- Create: `theo/services/web/app/research/hypotheses/page.tsx`

#### Phase 3: Personalized Dashboard (Week 4)

- Modify: `theo/services/web/app/page.tsx` (replace landing)
- Create: `theo/services/api/app/routes/dashboard.py`
- Sections: stats, activity, discoveries, quick actions

#### Phase 4: Citation Manager (Week 5-6)

**4.1 Citation Export**
- Create: `theo/services/api/app/export/citations.py`
- Formats: APA, Chicago, SBL, BibTeX

**4.2 Bibliography Builder**
- Create: `theo/services/web/app/bibliography/page.tsx`

**4.3 Zotero Integration** (optional)
- Create: `theo/services/api/app/export/zotero.py`

---

### Deployment

#### Install Dependencies
```bash
pip install -r requirements.txt
```

#### First-Time Setup
```bash
## Download NLI model (~400MB, one-time)
python -c "from transformers import AutoModel; AutoModel.from_pretrained('microsoft/deberta-v3-base-mnli')"

## Start services
.\start-theoria.ps1
```

#### Verify
```bash
## Check logs
tail -f logs/api.log | grep "Discovery scheduler"

## Should see: "Discovery scheduler started successfully"
```

---

### Key Files

#### Created This Session
- `theo/services/api/app/workers/discovery_scheduler.py`
- `theo/domain/discoveries/contradiction_engine.py`
- `tests/domain/discoveries/test_contradiction_engine.py`
- `docs/DISCOVERY_SCHEDULER.md`
- `docs/CONTRADICTION_DETECTION.md`
- `docs/AGENT_AND_PROMPTING_GUIDE.md`
- `HANDOFF_NEXT_PHASE.md`

#### Modified This Session
- `requirements.txt` (added apscheduler, transformers, torch, sentencepiece)
- `theo/services/api/app/main.py` (scheduler lifecycle)
- `theo/domain/discoveries/__init__.py` (export engine)
- `theo/services/api/app/discoveries/service.py` (integrate contradiction detection)
- `docs/INDEX.md` (added links)

#### Important Existing Files
- `theo/domain/discoveries/engine.py` (pattern detection)
- `theo/services/api/app/discoveries/service.py` (service layer)
- `theo/services/api/app/discoveries/tasks.py` (background tasks)
- `theo/services/api/app/routes/discoveries.py` (API endpoints)
- `theo/services/web/app/discoveries/page.tsx` (frontend)

---

### Testing

#### Unit Tests
```bash
pytest tests/domain/discoveries/test_contradiction_engine.py -v
```

#### Integration Tests
```bash
pytest tests/api/test_discovery_integration.py -v
```

#### Manual Testing
1. Upload document → discoveries appear within 30s
2. Wait 30 minutes → periodic refresh runs
3. Check `/api/discoveries?type=contradiction`

---

### Configuration

```bash
## Discovery scheduler interval (default: 30 minutes)
export THEORIA_DISCOVERY_INTERVAL=30

## Disable periodic scheduler
export THEORIA_DISABLE_DISCOVERY_SCHEDULER=true

## NLI model configuration
export THEORIA_NLI_MODEL=microsoft/deberta-v3-base-mnli
export THEORIA_CONTRADICTION_THRESHOLD=0.7
export THEORIA_MIN_CONTRADICTION_CONFIDENCE=0.6
```

---

### Success Metrics

#### Phase 1 (Discovery Engine)
- ✅ All 6 discovery types generating discoveries
- ✅ Average 10+ discoveries per user with 50+ documents
- ✅ Discovery generation < 30s for typical corpus
- ✅ User feedback: 70%+ find discoveries helpful

#### Phase 2 (Agent Reasoning)
- ✅ 30%+ of chat queries use reasoning modes
- ✅ Reasoning traces viewed by 50%+ of users
- ✅ User feedback: 80%+ find reasoning helpful

#### Phase 3 (Dashboard)
- ✅ 80%+ of sessions start from dashboard
- ✅ User feedback: 85%+ prefer dashboard

#### Phase 4 (Citations)
- ✅ 40%+ of users export citations
- ✅ User feedback: 90%+ find export useful

---

**Status:** Phase 1.1 complete (2/6 discovery types working)  
**Next:** Phase 1.2 - Gap Analysis with BERTopic  
**Timeline:** 6-8 weeks to complete Cognitive Scholar phases

---

## Strict Typing Follow-up

## Handoff: MyPy Type Error Fixes

**Session Date:** October 17, 2025  
**Last Update:** October 17, 2025 (Quick Wins Complete)  
**Objective:** Fix all mypy errors reported in CI  
**Status:** ✅ Major Progress - Infrastructure Complete, 1678 errors remaining (down from ~2000+)

---

### 🎯 What Was Accomplished

#### 1. Type Stub Files Updated (.pyi files)

Complete overhaul of type stub files to match actual model implementations:

##### `typings/theo/services/api/app/db/models.pyi`
**Added missing attributes to `Document` class:**
- `authors: list[str] | None`
- `doi`, `venue`, `year`, `theological_tradition`, `topic_domains`
- `sha256`, `storage_path`, `enrichment_version`, `provenance_score`
- `channel`, `video_id`, `duration_seconds`, `bib_json`, `pub_date`
- `passages`, `annotations` relationships

**Added missing model classes (previously causing "has no attribute" errors):**
- ✅ `Passage` - Full class definition with all attributes
- ✅ `PassageVerse` - Association table model
- ✅ `DocumentAnnotation` - Annotations model
- ✅ `Creator`, `CreatorClaim` - Creator-related models
- ✅ `Video` - Video metadata model
- ✅ `TranscriptSegment`, `TranscriptSegmentVerse` - Transcript models
- ✅ `TranscriptQuote`, `TranscriptQuoteVerse` - Quote models
- ✅ `FeedbackEventAction` - Enum for feedback actions
- ✅ `ContradictionSeed`, `HarmonySeed`, `CommentaryExcerptSeed` - Seed models
- ✅ `CaseObjectType`, `CaseSource`, `CaseObject` - Case builder models

##### `typings/theo/services/api/app/models/search.pyi`
**Enhanced `HybridSearchRequest`:**
- Added `cursor: str | None`
- Added `limit: int | None`
- Added `mode: str`

**Enhanced `HybridSearchResult`:**
- Added `text: str`, `raw_text: str | None`
- Added `rank: int`
- Added score fields: `document_score`, `document_rank`, `lexical_score`, `vector_score`, `osis_distance`
- Added `model_dump()` method

**Enhanced `HybridSearchFilters`:**
- Added `model_dump()` method

##### `typings/theo/services/api/app/models/verses.pyi`
**Added missing verse-related models:**
- ✅ `VerseMention` - Mention model with passage and context
- ✅ `VerseGraphNode` - Graph node representation
- ✅ `VerseGraphEdge` - Graph edge with relationship types
- ✅ `VerseGraphFilters` - Filtering for graph queries
- ✅ `VerseGraphResponse` - Complete graph response
- ✅ `VerseTimelineBucket` - Timeline aggregation
- ✅ `VerseTimelineResponse` - Timeline response

---

#### 2. Removed Unused Type: Ignore Comments (12 instances)

**Files cleaned:**
- ✅ `theo/services/api/app/ingest/stages/base.py` - telemetry import
- ✅ `theo/services/api/app/ingest/stages/enrichers.py` - context parameter (2 classes)
- ✅ `theo/services/api/app/ingest/stages/persisters.py` - context parameter (2 classes)
- ✅ `theo/services/api/app/ingest/stages/parsers.py` - context parameter (4 classes)
- ✅ `theo/services/api/app/ingest/stages/fetchers.py` - context parameter (3 classes)
- ✅ `theo/services/api/app/ingest/parsers.py` - HTMLParser overrides (3 methods)
- ✅ `theo/services/api/app/ingest/network.py` - redirect_request override
- ✅ `theo/services/api/app/ingest/pipeline.py` - _UrlDocumentPersister.persist
- ✅ `theo/services/api/app/case_builder/ingest.py` - meta dict access

---

#### 3. Added Missing Type Annotations

**Ingestion Pipeline Stages:**
- All `parse()`, `persist()`, `fetch()`, `enrich()` methods now have proper signatures
- Changed from `def method(self, *, context, state: dict[str, Any])` 
- To: `def method(self, *, context: Any, state: dict[str, Any]) -> dict[str, Any]`

**Network Module (`theo/services/api/app/ingest/network.py`):**
- `ensure_url_allowed(settings: Any, url: str) -> None`
- `ensure_resolved_addresses_allowed(settings: Any, addresses: tuple[IPAddress, ...]) -> None`
- `fetch_web_document(settings: Any, url: str, *, opener_factory: Any = build_opener) -> tuple[str, dict[str, str | None]]`
- `resolve_fixtures_dir(settings: Any) -> Path | None`
- `LoopDetectingRedirectHandler.redirect_request(req: Any, fp: Any, code: int, msg: str, headers: Any, newurl: str) -> Any`

**HTML Parser (`theo/services/api/app/ingest/parsers.py`):**
- `handle_starttag(tag: str, attrs: list[tuple[str, str | None]]) -> None`
- `handle_endtag(tag: str) -> None`
- `handle_data(data: str) -> None`

**Helper Functions (`theo/services/api/app/ingest/stages/persisters.py`):**
- `_set_chunk_metrics(context: Any, parser_result: Any) -> None`

**Case Builder (`theo/services/api/app/case_builder/ingest.py`):**
- `_passage_meta(passage: Passage) -> dict[str, Any] | None`
- `_source_meta(document: Document) -> dict[str, Any] | None`
- Added `from typing import Any`

---

#### 4. Fixed Module Export Issues

**`theo/services/api/app/ingest/osis.py`:**
```python
__all__ = [
    "expand_osis_reference",
    "format_osis",
    "osis_to_readable",
    "DetectedOsis",
    "combine_references",
    "detect_osis_references",
    "canonical_verse_range",
    "osis_intersects",
    "classify_osis_matches",
]
```
- Fixed: `Module "theo.services.api.app.ingest.osis" does not explicitly export attribute "expand_osis_reference"`

**`theo/services/api/app/routes/export.py`:**
```python
__all__ = ["router", "api_router", "ExportError"]
```
- Fixed: Test imports of `ExportError` now work

---

#### 5. Quick Wins Completed (Latest Session)

**Files Modified:**
- ✅ `theo/services/api/app/ai/reasoning/chain_of_thought.py` - Added `Any` import, typed 5 `dict` parameters to `dict[str, Any]`
- ✅ `theo/services/api/app/enrich/metadata.py` - Removed unreachable code (2 instances), added `Settings` type annotation to `__init__`
- ✅ `theo/services/api/app/db/verse_graph.py` - Added type annotations to `_range_condition()` function

**Dependency Installed:**
- ✅ `types-cachetools` - Fixes 1 import-untyped error

**Errors Fixed:** 18 total
- `type-arg` errors: ~5 fixed (bare `dict` → `dict[str, Any]`)
- `unreachable` errors: 2 fixed (redundant isinstance checks removed)
- `no-untyped-def` errors: 2 fixed (added function annotations)
- `import-untyped` errors: 1 fixed (types-cachetools installed)

**New Baseline:** 1678 errors (down from 1696)

---

### 📊 Current Status

#### MyPy Results
```
Found 1678 errors in 69 files (checked 39 source files)
```

**Progress:** 
- Initial: ~2000+ errors
- After infrastructure work: 1696 errors (71 files)
- After quick wins: 1678 errors (69 files) ⬇️ **18 errors fixed**

#### Error Categories Remaining

1. **`no-any-return`** (~50+ instances)
   - Functions declared to return specific types but returning `Any`
   - Primarily in: `theo/services/api/app/ai/clients.py`
   - Examples: Functions returning `str` but extracting from untyped JSON

2. **`type-arg`** (~10 instances) ⬇️ _5 fixed_
   - Missing type parameters for generic types
   - `dict` → `dict[str, Any]`
   - `set` → `set[str]`
   - `list` → `list[str]`
   - Remaining files need review

3. **`unreachable`** (~3 instances) ⬇️ _2 fixed_
   - Unreachable code statements
   - Remaining: Check `theo/services/api/app/ai/clients.py`

4. **`attr-defined`** (~10 instances)
   - Pydantic model methods not recognized (e.g., `model_dump`, `model_rebuild`)
   - Document construction issues
   - Files: `theo/services/api/app/models/documents.py`, `theo/services/api/app/analytics/telemetry.py`

5. **`name-defined`** (~3 instances)
   - Undefined names: `RAGAnswer`
   - File: `theo/services/api/app/ai/rag/cache.py`

6. **`call-arg`** (~5 instances)
   - Unexpected keyword arguments
   - Document/model constructor mismatches
   - Files: `theo/services/api/app/analytics/topics.py`, `theo/services/api/app/routes/export.py`

7. **`no-untyped-def`** (~1 instance) ⬇️ _2 fixed_
   - Functions missing type annotations
   - Remaining: Check `theo/services/api/app/infra/ingestion_service.py:288`

8. **`import-untyped`** ✅ _RESOLVED_
   - ~~Missing stub for `cachetools` library~~
   - Fixed: `types-cachetools` installed

9. **`assignment`** (~2 instances)
   - Incompatible type assignments
   - File: `theo/services/api/app/ai/clients.py`

---

### 🗂️ Files Modified

#### Type Stub Files (Complete Rewrites)
1. `typings/theo/services/api/app/db/models.pyi` - **143 lines** (was 26 lines)
2. `typings/theo/services/api/app/models/search.pyi` - Added attributes and methods
3. `typings/theo/services/api/app/models/verses.pyi` - **83 lines** (was 13 lines)

#### Source Files (Type Annotations Added)
4. `theo/services/api/app/ingest/stages/base.py`
5. `theo/services/api/app/ingest/stages/enrichers.py`
6. `theo/services/api/app/ingest/stages/persisters.py`
7. `theo/services/api/app/ingest/stages/parsers.py`
8. `theo/services/api/app/ingest/stages/fetchers.py`
9. `theo/services/api/app/ingest/parsers.py`
10. `theo/services/api/app/ingest/network.py`
11. `theo/services/api/app/ingest/pipeline.py`
12. `theo/services/api/app/ingest/osis.py`
13. `theo/services/api/app/case_builder/ingest.py`
14. `theo/services/api/app/routes/export.py`

---

### 🗂️ Files Modified (This Session)

#### Quick Wins Completed
1. ✅ `theo/services/api/app/ai/reasoning/chain_of_thought.py` - Generic type parameters
2. ✅ `theo/services/api/app/enrich/metadata.py` - Unreachable code removed, type annotations added
3. ✅ `theo/services/api/app/db/verse_graph.py` - Function type annotations
4. ✅ Installed: `types-cachetools`

---

### 🚀 Next Steps (Priority Order)

#### High Priority (Remaining Quick Wins)

1. **Find Remaining Generic Type Parameters** (~10 errors)
   - Search codebase for bare `dict`, `set`, `list` without type parameters
   - Focus on API modules under strict typing rules

2. **Check Remaining Unreachable Code** (~3 errors)
   - `theo/services/api/app/ai/clients.py` - may have remaining instances

3. **Add Missing Function Annotation** (~1 error)
   - `theo/services/api/app/infra/ingestion_service.py:288`

#### Medium Priority (More Complex)

5. **Fix `no-any-return` Errors** (~50 errors)
   - **Strategy:** Add explicit type casts or assertions
   - **Primary file:** `theo/services/api/app/ai/clients.py`
   - **Pattern:** Functions extracting from untyped JSON/dicts
   - **Solution examples:**
     ```python
     # Before
     def get_value(data: dict) -> str:
         return data["key"]  # error: Returning Any from function declared to return "str"
     
     # After
     def get_value(data: dict[str, Any]) -> str:
         value = data["key"]
         if not isinstance(value, str):
             raise ValueError("Expected string")
         return value
     ```

6. **Fix Pydantic Model Issues** (~10 errors)
   - Update stub files or add `# type: ignore` for Pydantic magic methods
   - Files: `theo/services/api/app/models/documents.py`, `theo/services/api/app/analytics/telemetry.py`
   - Issue: `model_dump`, `model_rebuild` not recognized on Pydantic models in stubs

7. **Fix Document Constructor Calls** (~5 errors)
   - `theo/services/api/app/analytics/topics.py:230` - Multiple unexpected keyword arguments
   - Need to check actual `Document` model vs stub definition for constructor
   - May need to update stub file `__init__` signature

#### Low Priority (Documentation/Cleanup)

8. **Define Missing Names**
   - `RAGAnswer` in `theo/services/api/app/ai/rag/cache.py:129`
   - Likely needs import or class definition

9. **Fix Assignment Incompatibilities**
   - `theo/services/api/app/ai/clients.py:838, 849`
   - Assigning `str | None` to `str` variables

---

### ⚠️ Important Notes

#### MyPy Configuration
The project uses **strict typing** for specific modules defined in `mypy.ini`:
```ini
[mypy-theo.services.api.app.*]
disallow_untyped_defs = True
disallow_incomplete_defs = True

[mypy-theo.services.api.app.routes.*]
disallow_untyped_defs = True
disallow_incomplete_defs = True

[mypy-theo.services.api.app.models.*]
disallow_untyped_defs = True
disallow_incomplete_defs = True
```

Many remaining errors are in modules **not** covered by strict typing rules (e.g., AI/RAG modules). Consider whether to extend strict typing to these areas.

#### Type Stub Philosophy
- Stub files (`.pyi`) should mirror the **runtime** structure of models
- They exist in `typings/` directory
- Key stub files now accurately reflect `theo.adapters.persistence.models` exports

#### Testing After Changes
Run mypy to verify changes:
```powershell
python -m mypy --config-file mypy.ini
```

**Baselines:**
- Previous: 1696 errors in 71 files
- Current: **1678 errors in 69 files** ⬇️ 18 errors fixed

---

### 🔍 Key Patterns for Future Fixes

#### Pattern 1: Stage Method Signatures
```python
## All ingestion stage methods should use this signature:
def method_name(self, *, context: Any, state: dict[str, Any]) -> dict[str, Any]:
    ...
```

#### Pattern 2: Generic Type Annotations
```python
## Always use typed generics
payload: dict[str, Any] = {}
tags: list[str] = []
visited: set[str] = set()
```

#### Pattern 3: Optional Dependency Imports
```python
## Keep type: ignore for optional dependencies
try:
    import optional_lib
except ImportError:
    optional_lib = None  # type: ignore[assignment]
```

#### Pattern 4: Pydantic Model Methods
```python
## If stub doesn't have model_dump, add it:
class MyModel:
    ...
    def model_dump(self, **kwargs: object) -> dict[str, object]: ...
```

---

### 📝 References

#### Related Documentation
- `mypy.ini` - MyPy configuration
- `typings/` - Type stub directory
- `theo/adapters/persistence/models.py` - Source of truth for ORM models

#### Key Commits in This Session
- Updated all type stub files for database models
- Added type annotations to ingestion pipeline stages
- Fixed module export issues for `expand_osis_reference` and `ExportError`
- Cleaned up unused `type: ignore` comments

---

### ✅ Session Completion Checklist

**Infrastructure (Initial Session):**
- [x] Type stubs updated for all database models
- [x] Ingestion pipeline stages properly typed
- [x] Module exports fixed
- [x] Unused type: ignore comments removed
- [x] Documentation created (this file)

**Quick Wins (Latest Session):**
- [x] Install missing type stubs (`types-cachetools`)
- [x] Fix generic type parameters in chain_of_thought.py (5 instances)
- [x] Remove unreachable code in metadata.py (2 instances)
- [x] Add missing function type annotations (2 functions)

**Still TODO:**
- [ ] Find and fix remaining ~10 generic type parameters
- [ ] Address ~50 `no-any-return` errors
- [ ] Fix Pydantic model stub issues (~10 errors)
- [ ] Fix Document constructor call-arg errors (~5 errors)

---

**Next Agent/Developer:** Start with "High Priority" quick wins above. The foundation is solid - remaining errors are mostly straightforward typing improvements. Good luck! 🚀

---

## Next Phase Roadmap

## Theoria - Next Phase Development Plan

> **Status:** Ready for implementation
> **Last Updated:** 2025-02-10
> **Estimated Timeline:** 6–8 weeks

---

### Executive Summary

The next delivery window advances the **Cognitive Scholar** initiative: durable hypothesis objects, gate-managed reasoning, and
structured debate workflows. The plan is organized around successive capability layers—gate, loop control, thought management,
debate orchestration, and prompt governance. Each phase concludes with demos and telemetry hooks to keep research UX and safety
in lockstep.

#### Current State ✅
- ✅ Frontend scaffolding for `/research/hypotheses`
- ✅ Prompt kernel prototypes for the Cognitive Gate
- ✅ Baseline Prompt-Observe-Update loop in production
- ✅ Reasoning telemetry primitives (trails, fallacy reports)
- ✅ Documentation and safety guardrails for agents

#### What's Next 🎯
1. Productionize Cognitive Gate v0 and ship hypothesis objects.
2. Swap the Prompt-Observe-Update loop to be gate-aware and log all outcomes.
3. Launch Thought Management System (TMS) v0 with persistence and admin tooling.
4. Orchestrate Debate Loop v0 and wire structured visualizations.
5. Deliver Meta-Prompt picker and finalize Beta readiness hardening.

---

### Phase 1 (Week 1–2): Hypothesis Objects & Cognitive Gate v0

#### Goals
- Persist research hypotheses with lifecycle metadata and evidence hooks.
- Stand up the Cognitive Gate service for admission control and policy enforcement.

#### Tasks
- **Hypothesis Schema & Storage**
  - Create migrations for `hypotheses`, `hypothesis_evidence`, and linking tables.
  - Implement repository/service layer APIs for CRUD and status transitions.
  - Backfill tests covering optimistic concurrency and soft-deletes.
- **Cognitive Gate Service v0**
  - Convert the prompt kernel into `theo/services/api/app/ai/gate/service.py`.
  - Implement score computation, policy thresholds, and audit logging.
  - Expose `/api/ai/gate/evaluate` endpoint with contract tests.
- **Integration & Telemetry**
  - Wire gate decisions into research/chat flows in `GuardedAnswerPipeline`.
  - Emit structured telemetry (scores, policy, overrides) to metrics stream.
  - Document gate operations, fail-open criteria, and override workflow in `docs/AGENT_AND_PROMPTING_GUIDE.md`.

### Phase 2 (Week 3): POU Loop Swap & Research UI Refresh

#### Goals
- Replace legacy evaluator with gate-managed control logic.
- Expose hypotheses and gate results in the research UI.

#### Tasks
- **POU Loop Swap**
  - Update `GuardedAnswerPipeline` to delegate to the Cognitive Gate.
  - Add fallback handling for gate errors (retry, degrade, operator alert).
  - Expand unit and integration tests to cover pass, reject, and override paths.
- **UI & API Updates**
  - Enhance `/research/hypotheses` page to display gate verdicts, scores, and timestamps.
  - Extend research API responses with hypothesis IDs and gate metadata.
  - Update docs and demos illustrating hypothesis creation and review flows.

### Phase 3 (Weeks 4–5): Thought Management System (TMS) v0

#### Goals
- Manage concurrent hypotheses, branching, and archival through a dedicated service.
- Provide operators with tooling to inspect and replay thought sequences.

#### Tasks
- **TMS Service Layer**
  - Implement `theo/services/api/app/ai/tms/service.py` with session lifecycle management.
  - Persist step history including prompt, agent, gate verdict, and outcome.
  - Create retention policy jobs for pruning inactive sessions.
- **Admin & Observability**
  - Build admin UI for TMS inspection (filter by hypothesis, gate verdict, outcome).
  - Add replay endpoint to re-run or audit sessions under new policies.
  - Instrument metrics for session duration, branch counts, and overrides.

### Phase 4 (Weeks 6): Debate Loop v0 & Visualization Layer v1

#### Goals
- Introduce orchestrated pro/con agents moderated by the Cognitive Gate.
- Visualize debates and hypothesis evolution in the research UI.

#### Tasks
- **Debate Orchestration**
  - Implement debate coordinator managing rounds, agent roles, and gate validations.
  - Persist debate transcripts linked to hypotheses and TMS sessions.
  - Establish safety guardrails, scoring rubric, and escalation paths for moderator intervention.
- **Visualization Layer v1**
  - Add timeline and graph components showing hypothesis confidence changes.
  - Surface gate/debate telemetry dashboards (admission rate, overrides, contention points).
  - Capture UX feedback checklist post-demo for iteration planning.

### Phase 5 (Week 7–8): Meta-Prompt Picker & Beta Hardening

#### Goals
- Allow researchers to select prompt presets aligned with their objectives.
- Harden the system for limited Beta release with telemetry, safety, and documentation updates.

#### Tasks
- **Meta-Prompt Picker**
  - Curate presets (Exploratory, Apologetic, Critical, Synthesis) with guardrail annotations.
  - Add UI controls to switch presets mid-session with validation warnings.
  - Track preset usage, satisfaction scores, and gate outcomes per preset.
- **Beta Hardening**
  - Run load tests for multi-hypothesis debate sessions; capture baseline metrics.
  - Expand adversarial test suite covering hallucination, citation drift, and prompt abuse.
  - Update onboarding documentation, create Beta feedback rubric, and finalize release checklist.

---

### Testing Strategy

#### Unit Tests
```bash
pytest tests/domain/hypotheses/ -v
pytest tests/api/ai/test_gate.py -v
pytest tests/api/ai/test_pou_loop.py -v
pytest tests/api/ai/test_tms.py -v
pytest tests/api/ai/test_debate.py -v
```

#### Integration & E2E
```bash
pytest tests/api/test_research_workflow.py -v
pytest tests/ui/test_hypothesis_workflow.py -v
npm run test:e2e:research --workspace theo/services/web
```

#### Telemetry & Safety Checks
```bash
python scripts/telemetry/validate_gate_events.py
pytest tests/safety/test_prompt_guardrails.py -v
```

---

### Dependencies & Risks

- **Model Variance** – Gate scoring depends on frontier models; capture calibration curves per provider.
- **Telemetry Overhead** – New metrics streams may impact ingestion; batch writes and monitor latency.
- **Operator Training** – Gate overrides and debate moderation require updated runbooks and demos.

---

### Communication Plan

- Weekly demo cadence showcasing gate decisions, TMS session replays, and debate transcripts.
- Async updates in `#theoria-research` summarizing gate metrics, hypothesis counts, and debate outcomes.
- Mid-cycle retrospective after Phase 3 to adjust scope for Beta hardening.

---

## Implementation Context

## Implementation Context for AI Agents

This document provides complete context for AI agents to continue development of the Theoria project.

---

### Project Overview

**Theoria** is an evidence-first theological research platform combining RAG (Retrieval-Augmented Generation), auto-discovery, and agent-based reasoning to help users explore biblical texts and theological documents.

**Tech Stack:**
- Frontend: Next.js 14 (App Router), React, TypeScript
- Backend: FastAPI, Python 3.12
- Database: PostgreSQL + pgvector
- AI: OpenAI GPT-4, transformers (HuggingFace), scikit-learn
- Deployment: Docker, Docker Compose

---

### Architecture Patterns

#### Hexagonal Architecture
The codebase follows hexagonal (ports & adapters) architecture:

```
theo/
├── domain/           # Core business logic (pure Python)
│   ├── discoveries/  # Discovery engines
│   └── repositories/ # Repository interfaces
├── application/      # Use cases and facades
│   └── facades/      # Database, settings, runtime
├── adapters/         # External integrations
│   └── research/     # Research providers
└── services/
    ├── api/          # FastAPI application
    └── web/          # Next.js frontend
```

**Key Principles:**
- Domain layer has no external dependencies
- Application layer orchestrates domain logic
- Adapters handle external systems
- Services expose functionality via APIs/UI

#### Discovery Engine Pattern

All discovery engines follow this pattern:

```python
from dataclasses import dataclass

@dataclass(frozen=True)
class XyzDiscovery:
    """Discovery result with metadata."""
    title: str
    description: str
    confidence: float  # 0.0 - 1.0
    relevance_score: float  # 0.0 - 1.0
    metadata: dict[str, object]

class XyzDiscoveryEngine:
    """Engine for detecting XYZ patterns."""
    
    def __init__(self, *, param1: type = default):
        """Initialize with configuration."""
        self.param1 = param1
    
    def detect(self, documents: Sequence[DocumentEmbedding]) -> list[XyzDiscovery]:
        """Detect patterns and return discoveries."""
        # 1. Validate input
        if len(documents) < min_required:
            return []
        
        # 2. Run detection algorithm
        results = self._run_detection(documents)
        
        # 3. Filter and rank
        filtered = [r for r in results if r.confidence >= threshold]
        filtered.sort(key=lambda x: x.confidence, reverse=True)
        
        # 4. Return top N
        return filtered[:max_results]
```

**Integration into DiscoveryService:**

```python
## theo/services/api/app/discoveries/service.py

def refresh_user_discoveries(self, user_id: str) -> list[Discovery]:
    documents = self._load_document_embeddings(user_id)
    
    # Run all engines
    pattern_discoveries = self.pattern_engine.detect(documents)
    contradiction_discoveries = self.contradiction_engine.detect(documents)
    xyz_discoveries = self.xyz_engine.detect(documents)  # Add new engine
    
    # Delete old discoveries
    self.session.execute(
        delete(Discovery).where(
            Discovery.user_id == user_id,
            Discovery.discovery_type.in_([
                DiscoveryType.PATTERN.value,
                DiscoveryType.CONTRADICTION.value,
                DiscoveryType.XYZ.value,  # Add new type
            ])
        )
    )
    
    # Persist all discoveries
    all_discoveries = (
        pattern_discoveries + 
        contradiction_discoveries + 
        xyz_discoveries  # Add new discoveries
    )
    
    for discovery in all_discoveries:
        record = Discovery(
            user_id=user_id,
            discovery_type=discovery.type,
            title=discovery.title,
            description=discovery.description,
            confidence=float(discovery.confidence),
            relevance_score=float(discovery.relevance_score),
            viewed=False,
            meta=dict(discovery.metadata),
            created_at=datetime.now(UTC),
        )
        self.session.add(record)
    
    self.session.commit()
    return all_discoveries
```

---

### Code Style & Conventions

#### Python

**Type Hints:**
```python
## Always use type hints
def function(param: str, optional: int | None = None) -> list[str]:
    pass

## Use from __future__ import annotations for forward refs
from __future__ import annotations
```

**Imports:**
```python
## Standard library
from __future__ import annotations
import logging
from datetime import UTC, datetime
from typing import Sequence

## Third-party
import numpy as np
from sqlalchemy import select

## Local
from theo.domain.discoveries import DiscoveryType
from ..models import Discovery
```

**Docstrings:**
```python
def function(param: str) -> int:
    """Short description.
    
    Longer description if needed.
    
    Args:
        param: Description of parameter
        
    Returns:
        Description of return value
        
    Raises:
        ValueError: When something goes wrong
    """
```

**Error Handling:**
```python
## Specific exceptions
try:
    result = risky_operation()
except SpecificError as exc:
    logger.exception("Context about what failed")
    raise CustomError("User-friendly message") from exc
```

#### TypeScript/React

**Component Structure:**
```tsx
// Use CSS modules
import styles from './Component.module.css';

interface ComponentProps {
  required: string;
  optional?: number;
}

export function Component({ required, optional = 0 }: ComponentProps) {
  const [state, setState] = useState<string>('');
  
  return (
    <div className={styles.container}>
      {/* Content */}
    </div>
  );
}
```

**API Calls:**
```tsx
// Use fetch with proper error handling
async function fetchData() {
  try {
    const response = await fetch('/api/endpoint', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(data),
    });
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    
    return await response.json();
  } catch (error) {
    console.error('Failed to fetch:', error);
    throw error;
  }
}
```

---

### Testing Patterns

#### Unit Tests

```python
## tests/domain/discoveries/test_xyz_engine.py

import pytest
from theo.domain.discoveries import XyzDiscoveryEngine, DocumentEmbedding

@pytest.fixture
def sample_documents():
    """Fixture providing test documents."""
    return [
        DocumentEmbedding(
            document_id="doc1",
            title="Test Document",
            abstract="Test abstract",
            topics=["test"],
            verse_ids=[43001001],
            embedding=[0.1] * 768,
            metadata={},
        ),
    ]

def test_engine_initialization():
    """Test engine initializes correctly."""
    engine = XyzDiscoveryEngine()
    assert engine.param1 == expected_default

def test_detect_with_valid_input(sample_documents):
    """Test detection with valid documents."""
    engine = XyzDiscoveryEngine()
    discoveries = engine.detect(sample_documents)
    
    assert len(discoveries) > 0
    assert discoveries[0].confidence >= 0.0
    assert discoveries[0].confidence <= 1.0

def test_detect_with_insufficient_documents():
    """Test detection fails gracefully with too few documents."""
    engine = XyzDiscoveryEngine()
    discoveries = engine.detect([])
    
    assert discoveries == []

@pytest.mark.slow
def test_detect_integration(sample_documents):
    """Integration test requiring external resources."""
    # Tests marked 'slow' can be skipped in CI
    pass
```

#### Integration Tests

```python
## tests/api/test_discovery_integration.py

def test_discovery_refresh_end_to_end(session, user_id):
    """Test full discovery refresh flow."""
    # 1. Setup: Create test documents
    documents = create_test_documents(session, user_id)
    
    # 2. Execute: Refresh discoveries
    discovery_repo = SQLAlchemyDiscoveryRepository(session)
    document_repo = SQLAlchemyDocumentRepository(session)
    service = DiscoveryService(discovery_repo, document_repo)
    discoveries = service.refresh_user_discoveries(user_id)
    
    # 3. Assert: Verify results
    assert len(discoveries) > 0
    
    # 4. Verify database state
    db_discoveries = session.query(Discovery).filter_by(user_id=user_id).all()
    assert len(db_discoveries) == len(discoveries)
```

---

### Database Patterns

#### Models

```python
## theo/services/api/app/db/models.py

from sqlalchemy import Column, Integer, String, Float, Boolean, DateTime, JSON
from sqlalchemy.dialects.postgresql import JSONB
from .base import Base

class Discovery(Base):
    __tablename__ = "discoveries"
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_id = Column(String, nullable=False, index=True)
    discovery_type = Column(String, nullable=False, index=True)
    title = Column(String, nullable=False)
    description = Column(Text, nullable=True)
    confidence = Column(Float, nullable=False, default=0.0)
    relevance_score = Column(Float, nullable=False, default=0.0)
    viewed = Column(Boolean, nullable=False, default=False, index=True)
    user_reaction = Column(String, nullable=True)
    created_at = Column(DateTime(timezone=True), nullable=False, index=True)
    meta = Column(JSONB, nullable=True)  # Type-specific metadata
```

#### Queries

```python
## Use SQLAlchemy 2.0 style
from sqlalchemy import select, delete

## Select
stmt = select(Discovery).where(
    Discovery.user_id == user_id,
    Discovery.viewed == False,
).order_by(Discovery.created_at.desc())
results = session.scalars(stmt).all()

## Delete
stmt = delete(Discovery).where(
    Discovery.user_id == user_id,
    Discovery.discovery_type == "pattern",
)
session.execute(stmt)
session.commit()
```

---

### API Patterns

#### FastAPI Routes

```python
## theo/services/api/app/routes/xyz.py

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session

from theo.application.facades.database import get_session
from ..models.xyz import XyzRequest, XyzResponse
from ..security import Principal, require_principal

router = APIRouter()

@router.get("/", response_model=list[XyzResponse])
def list_xyz(
    filter_param: str | None = None,
    principal: Principal = Depends(require_principal),
    session: Session = Depends(get_session),
) -> list[XyzResponse]:
    """List XYZ resources."""
    user_id = principal["subject"]
    
    # Query database
    results = query_xyz(session, user_id, filter_param)
    
    # Convert to response models
    return [XyzResponse.model_validate(r) for r in results]

@router.post("/", status_code=status.HTTP_201_CREATED)
def create_xyz(
    request: XyzRequest,
    principal: Principal = Depends(require_principal),
    session: Session = Depends(get_session),
) -> XyzResponse:
    """Create new XYZ resource."""
    user_id = principal["subject"]
    
    # Validate and create
    xyz = create_xyz_resource(session, user_id, request)
    
    return XyzResponse.model_validate(xyz)
```

#### Pydantic Models

```python
## theo/services/api/app/models/xyz.py

from pydantic import BaseModel, Field

class XyzRequest(BaseModel):
    """Request model for creating XYZ."""
    name: str = Field(..., min_length=1, max_length=255)
    optional_field: int | None = Field(None, ge=0)

class XyzResponse(BaseModel):
    """Response model for XYZ."""
    id: int
    name: str
    created_at: str
    
    model_config = {"from_attributes": True}  # Enable ORM mode
```

---

### Common Pitfalls & Solutions

#### 1. Model Loading Performance

**Problem:** Loading large ML models on every request

**Solution:** Lazy loading with caching
```python
class Engine:
    def __init__(self):
        self._model = None
    
    def _load_model(self):
        if self._model is None:
            self._model = load_expensive_model()
```

#### 2. Memory Issues with Large Corpora

**Problem:** Loading all embeddings into memory

**Solution:** Batch processing and streaming
```python
def process_documents(documents):
    batch_size = 100
    for i in range(0, len(documents), batch_size):
        batch = documents[i:i + batch_size]
        yield process_batch(batch)
```

#### 3. Database Connection Leaks

**Problem:** Not closing sessions properly

**Solution:** Use context managers
```python
with get_session() as session:
    # Work with session
    pass  # Automatically closed
```

#### 4. Frontend State Management

**Problem:** Prop drilling and scattered state

**Solution:** Use React Context or state management library
```tsx
// Create context
const DiscoveryContext = createContext<DiscoveryContextType | null>(null);

// Provider
export function DiscoveryProvider({ children }) {
  const [discoveries, setDiscoveries] = useState([]);
  return (
    <DiscoveryContext.Provider value={{ discoveries, setDiscoveries }}>
      {children}
    </DiscoveryContext.Provider>
  );
}

// Consumer
function Component() {
  const { discoveries } = useContext(DiscoveryContext);
}
```

---

### Development Workflow

#### 1. Create Feature Branch
```bash
git checkout -b feature/gap-analysis
```

#### 2. Implement Feature
- Write tests first (TDD)
- Implement domain logic
- Integrate into service layer
- Add API endpoints
- Update frontend (if needed)
- Write documentation

#### 3. Run Tests
```bash
## Unit tests
pytest tests/domain/discoveries/test_gap_engine.py -v

## Integration tests
pytest tests/api/test_discovery_integration.py -v

## All tests
pytest tests/ -v

## With coverage
pytest tests/ --cov=theo --cov-report=html
```

#### 4. Type Checking
```bash
mypy theo/
```

#### 5. Linting
```bash
ruff check theo/
ruff format theo/
```

#### 6. Manual Testing
```bash
## Start services
.\start-theoria.ps1

## Test API
curl http://localhost:8000/api/discoveries

## Test frontend
## Open http://localhost:3000/discoveries
```

#### 7. Documentation
- Update relevant .md files
- Add docstrings to new functions
- Update HANDOFF documents if needed

---

### Environment Setup

#### Required Environment Variables

```bash
## Database
DATABASE_URL=postgresql://user:pass@localhost:5432/theoria

## OpenAI
OPENAI_API_KEY=sk-...

## Optional: Discovery configuration
THEORIA_DISCOVERY_INTERVAL=30
THEORIA_NLI_MODEL=microsoft/deberta-v3-base-mnli
THEORIA_CONTRADICTION_THRESHOLD=0.7
```

#### Local Development

```bash
## Install dependencies
pip install ".[api]" -c constraints/api.txt
pip install ".[ml]" -c constraints/ml.txt
pip install ".[dev]" -c constraints/dev.txt

## Setup database
docker-compose up -d postgres

## Run migrations
python -m theo.services.api.app.db.run_sql_migrations

## Start API
cd theo/services/api
uvicorn app.main:app --reload

## Start frontend (separate terminal)
cd theo/services/web
npm install
npm run dev
```

---

### Debugging Tips

#### 1. Enable Debug Logging
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

#### 2. Use IPython for Interactive Debugging
```python
## Add breakpoint
import IPython; IPython.embed()
```

#### 3. Check Database State
```bash
## Connect to database
psql $DATABASE_URL

## Query discoveries
SELECT id, discovery_type, title, confidence FROM discoveries WHERE user_id = 'test';
```

#### 4. Inspect API Requests
```bash
## Use httpie for better formatting
http GET localhost:8000/api/discoveries Authorization:"Bearer $TOKEN"
```

#### 5. Frontend Debugging
```tsx
// Use React DevTools
console.log('State:', state);

// Network tab in browser DevTools
// Check API responses
```

---

### Key Dependencies

#### Python
- `fastapi` - Web framework
- `sqlalchemy` - ORM
- `pydantic` - Data validation
- `transformers` - HuggingFace models
- `torch` - PyTorch
- `scikit-learn` - ML algorithms
- `numpy` - Numerical computing
- `apscheduler` - Task scheduling

#### TypeScript/React
- `next` - React framework
- `react` - UI library
- `typescript` - Type safety
- `lucide-react` - Icons

---

### Resources

#### Documentation
- `docs/INDEX.md` - Master documentation index
- `docs/AGENT_AND_PROMPTING_GUIDE.md` - Agent architecture
- `docs/DISCOVERY_FEATURE.md` - Discovery system spec
- `HANDOFF_NEXT_PHASE.md` - Development roadmap
- `HANDOFF_SESSION_2025_10_15.md` - Latest session summary

#### Code Examples
- `theo/domain/discoveries/engine.py` - Pattern detection (reference)
- `theo/domain/discoveries/contradiction_engine.py` - Contradiction detection (reference)
- `theo/services/api/app/discoveries/service.py` - Service integration (reference)

#### External Resources
- FastAPI docs: https://fastapi.tiangolo.com
- SQLAlchemy docs: https://docs.sqlalchemy.org
- HuggingFace docs: https://huggingface.co/docs
- Next.js docs: https://nextjs.org/docs

---

**Last Updated:** 2025-01-15  
**For Questions:** See documentation in `docs/` directory

